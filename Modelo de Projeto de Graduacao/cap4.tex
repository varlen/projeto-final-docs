\chapter{Implementação}
\label{cap4}

\paragraph{} Este capítulo dedica-se a aprofundar a discussão sobre a solução criada, suas premissas, restrições e motivações. O capitulo se encerra com o detalhamento da solução e de seus componentes.

\section{Requisitos e Limitações}

\paragraph{} A principal premissa a ser levada em consideração para implementação é que a estrutura dos dados deve ser conservada. Isso significa que as tabelas, as colunas, seus tipos e suas restrições relacionais, como chaves primárias e estrangeiras, deverão manter a compatibilidade com o banco de dados de entrada.

\paragraph{} Isso reduz a gama de técnicas de anonimização passiveis de utilização neste trabalho, pois algumas destas dependem de operações que alteram os tipos semânticos dos dados. Por exemplo, a já apresentada anteriormente, substituição de uma idade específica (27 anos) por uma faixa etária (20-30 anos) para atingir k-anonimização.

\paragraph{} Para colunas cujos valores são numéricos, este trabalho abre mão da fidelidade estatística por preferência a simplicidade de implementação. Colunas numéricas serão anonimizadas a partir da substituição por uma distribuição uniforme.

\paragraph{} Deste modo, a ferramenta de anonimização projetada ao longo deste trabalho visa prioritariamente cumprir o caso de uso em que um terceiro deve ter acesso à um banco de dados análogo, preenchido com dados gerados, com mesmo sentido semantico. Mantém-se um subconjunto da utilidade original enquanto os dados são dessensibilizados, assim como se é esperado de um sistema de anonimização.

\paragraph{} Ainda com intuito de simplificar a implementação, ao usar componentes cuja base é aprendizado de máquina, este trabalho se restringe a utilizar modelos prontos ao invés de treinar seus próprios modelos.

\paragraph{} Com a intenção de criar uma solução extensível e reutilizável, optou-se por desenvolvimento dentro das premissas adequadas para software livre, de código aberto e disponibilizado na plataforma GitHub.

\section{Tecnologias Utilizadas}

\paragraph{} O sistema implementado é capaz de gerar um banco de dados relacional anonimizado a partir de um banco de dados original, a partir da substituição dos dados reais por dados gerados, com mesmos tipos e estrutura.

\paragraph{} A escolha de tecnologias para implementação tomou como critério a existência de bibliotecas para realizar as manipulações de dados previstas, facilidade de reuso, disponibilidade de documentação pública e também a familiaridade do autor.

\paragraph{} Este trabalho utilizou Python como linguagem de programação principal tendo a biblioteca SQLAlchemy como provedor de acesso ao banco de dados para compatibilidade com multiplos Sistemas de Gerenciamento de Banco de Dados. No decorrer do processo de desenvolvimento, optou-se por restringir a implementação inicial existente em um único sistema de banco de dados relacional, especificamente Postgres.

\paragraph{} Visando-se a expansibilidade futura, o código foi implementado de forma a definir pontos de extensão que permitem à um usuário interessado adicionar compatibilidade com outros SGBDs.

\section{Componentes}

\paragraph{} Os componentes a seguir são os blocos lógicos do software e representam abstrações de alto nível das partes do sistema, visando facilitar o entendimento da solução como um todo.

\paragraph{} Cada componente realiza operações encadeadas dentro de um fluxo único de transformação dos dados que se inicia com a leitura do banco de dados que se deseja disponibilizar de maneira a garantir a privacidade e termina com a população de um novo banco de dados. A seguir está a descrição ordenada de cada componente:

\subsection{Analisador de Banco de Dados}

\paragraph{} O analisador de banco de dados é o componente responsável pelo inicio do fluxo de processamento da aplicação, obtendo as informações sobre o banco de dados e seus metadados a serem armazenadas em uma estrutura de dados comum que será utilizada posteriormente.

\paragraph{} Essa estrutura de dados é serializada como um arquivo de texto no formato JSON e persistida em disco. Isso permite que um passo seguinte do fluxo de processamento possa reutilizar o resultado de uma execução prévia deste componente, removendo a necessidade de um novo acesso ao banco de dados de origem.

\paragraph{} O analisador de banco de dados inclui o analisador de estrutura e o analisador de tipos semânticos.

\subsubsection{Analisador de Estrutura}

\paragraph{} É o subcomponente do analisador de banco de dados responsável por capturar o desenho do banco de dados original, trazendo para o fluxo de dados suas colunas com os respectivos tipos atômicos e tabelas, além de amostras e estatísticas dos dados, a partir da realização das consultas necessarias para obtenção destas informações.

\paragraph{} Este componente deve ser disponibilizado em uma implementação própria para cada dialeto de banco de dados a ser suportado.

\paragraph{} Isso é uma restrição causada pelo fato de que cada dialeto de banco de dados possui o seus próprios detalhes de implementação para além da especificação SQL e nem todos os comandos são universalmente compatíveis.

\subsubsection{Analisador de Tipos Semânticos}

\paragraph{} O analisador de tipos semânticos é o componente responsável por obter o significado de uma coluna dentro do contexto das informações presentes no banco de dados a partir de suas amostras e é aplicado em colunas textuais para permitir a futura geração de dados semanticamente coerentes com o banco de dados original.

\paragraph{} Este processo pode ser feito a partir das tecnicas previamente apresentadas como busca em dicionário e expressão regulares. Porém, estas tecnicas apresentam limitações que as tornam inconvenientes para obtenção de alguns tipos semânticos importantes como endereço, etc.

\paragraph{} Como uma tentativa de contornar este problema e melhorar a inferência de tipos semânticos, este componente utiliza uma solução externa criada a partir de técnicas de aprendizado de máquina.

\paragraph{} Este sistema externo, chamado SATO\cite{zhang2019sato}, é integrada à solução final a partir de chamadas HTTP. Para cada tabela do banco de origem, o analisador de tipos semânticos cria uma amostra no formato CSV contendo um subconjunto dos seus registros e a envia para a rota de classficação do SATO. Utilizou-se um modelo pré-treinado, incluido no repositório do SATO, chamado Type78.

\paragraph{} Desta forma, é possível obter o tipo semântico de colunas que não poderiam ser processadas apenas com técnicas deterministicas.

\paragraph{} A classificação semântica de cada coluna pode então ser utilizada em etapas seguintes do fluxo para geração de dados análogos.

\subsubsection{Extrator Numérico}

\paragraph{} Para colunas de tipos numéricos, há um processamento que visa substituir o conjunto de dados originais com um conjunto cuja distribuição é análoga.

\paragraph{} Para isso, coletam-se amostras do conjunto original. Essas amostras são ordenadas. Um número aleatório é sorteado de uma distribuição uniforme entre 0 e 1 e multiplicado pelo número de amostras.

\paragraph{} A parte inteira deste número sorteado e escalado é utilizada como índice para acessar uma das amostras ordenadas do conjunto original.

\paragraph{} Realiza-se então a interpolação linear dessa amostra e da amostra seguinte, com pesos proporcionais a parte fracionária do número índice. Essa operação gera um novo número que é armazenado em um vetor.

\paragraph{} Esse processo é repetido até gerar um novo conjunto de números que caracteriza o conjunto numérico original. Quando ocorre a geração de dados, este novo conjunto passa pelo mesmo processo para ser expandido e gerar o conteúdo de uma coluna numérica anonimizada.

\paragraph{} Um estudo aprofundado visando discutir valores ótimos para o tamanho do conjunto caracterizador e também das alterações nas funções estatísticas está fora do escopo deste trabalho e será deixada para eventuais continuações.

\subsection{Gerador de Dados}

\paragraph{} O Gerador de dados é o componente responsável pela geração da carga de saída do fluxo de processamento.

\paragraph{} Este componente requer como entrada o arquivo contendo as especificações geradas pelos componentes anteriores e utiliza como parâmetro para geração da estrutura e do conteúdo de um novo banco de dados.

\paragraph{} O primeiro passo do fluxo de geração de dados é a criação das tabelas e suas relações, incluindo chaves primárias e extrangeiras.

\paragraph{} Então, gera-se o conteúdo das tabelas. Para colunas que não possuem um elo com outra tabela, ou seja, que não são chaves estrangeiras, o dado é gerado utilizando um gerador selecionado a partir dos seus tipos atômico e semantico.

\paragraph{} As colunas cujo dado é oriundo de outra tabela a partir de uma relação têm sua criação postergada até que a coluna de origem tenha dados gerados. Os dados gerados da origem são selecionados aleatóriamente para a coluna de destino.