\chapter{Implementação}
\label{cap4}

\paragraph{} Este capítulo dedica-se a aprofundar a discussão sobre a solução criada, suas premissas, restrições e motivações. O capitulo se encerra com o detalhamento da solução e de seus componentes.

\section{Requisitos e Limitações}

\paragraph{} A principal premissa a ser levada em consideração para implementação é que a estrutura dos dados deve ser conservada. Isso significa que as tabelas, as colunas, seus tipos e suas restrições relacionais, como chaves primárias e estrangeiras, deverão manter a compatibilidade com o banco de dados de entrada.

\paragraph{} Isso reduz a gama de técnicas de anonimização passiveis de utilização neste trabalho, pois algumas destas dependem de operações que alteram os tipos semânticos dos dados. Por exemplo, a já apresentada anteriormente, substituição de uma idade específica (27 anos) por uma faixa etária (20-30 anos) para atingir k-anonimização.

\paragraph{} Para colunas cujos valores são numéricos, este trabalho abre mão da fidelidade estatística por preferência a simplicidade de implementação. Colunas numéricas serão anonimizadas a partir da substituição por uma distribuição uniforme.

\paragraph{} Deste modo, a ferramenta de anonimização projetada ao longo deste trabalho visa prioritariamente cumprir o caso de uso em que um terceiro deve ter acesso à um banco de dados análogo, preenchido com dados gerados, com mesmo sentido semantico. Mantém-se um subconjunto da utilidade original enquanto os dados são dessensibilizados, assim como se é esperado de um sistema de anonimização.

\paragraph{} Ainda com intuito de simplificar a implementação, ao usar componentes cuja base é aprendizado de máquina, este trabalho se restringe a utilizar modelos prontos ao invés de treinar seus próprios modelos.

\paragraph{} Com a intenção de criar uma solução extensível e reutilizável, optou-se por desenvolvimento dentro das premissas adequadas para software livre, de código aberto e disponibilizado na plataforma GitHub.

\section{Tecnologias Utilizadas}

\paragraph{} O sistema implementado é capaz de gerar um banco de dados relacional anonimizado a partir de um banco de dados original, a partir da substituição dos dados reais por dados gerados, com mesmos tipos e estrutura.

\paragraph{} A escolha de tecnologias para implementação tomou como critério a existência de bibliotecas para realizar as manipulações de dados previstas, facilidade de reuso, disponibilidade de documentação pública e também a familiaridade do autor.

\paragraph{} Este trabalho utilizou Python como linguagem de programação principal tendo a biblioteca SQLAlchemy como provedor de acesso ao banco de dados para compatibilidade com multiplos Sistemas de Gerenciamento de Banco de Dados. No decorrer do processo de desenvolvimento, optou-se por restringir a implementação inicial existente em um único sistema de banco de dados relacional, especificamente Postgres.

\paragraph{} O código específico de banco de dados foi implementado de forma a definir pontos de extensão a partir de módulos. O usuário pode adicionar seus módulos implementando compatibilidade com outros sistemas de bancos de dados e definir qual módulo deverá ser utilizado ao executar o sistema.

\paragraph{} O módulo de banco de dados precisa incluir um conjunto de consultas pré-definidas. Essas consultas são utilizadas para extrair amostras e metadados do banco de dados originário e devem utilizar a capacidade de introspecção específica de cada implementação de banco de dados.

\section{Componentes}

\paragraph{} Os componentes a seguir são os blocos lógicos do software e representam abstrações de alto nível das partes do sistema, visando facilitar o entendimento da solução como um todo.

\paragraph{} Cada componente realiza operações encadeadas dentro de um fluxo único de transformação dos dados que se inicia com a leitura do banco de dados que se deseja disponibilizar de maneira a garantir a privacidade e termina com a população de um novo banco de dados. A seguir está a descrição ordenada de cada componente:

\subsection{Analisador de Banco de Dados}

\paragraph{} O analisador de banco de dados é o componente responsável pelo inicio do fluxo de processamento da aplicação, obtendo as informações sobre o banco de dados e seus metadados a serem armazenadas em uma estrutura de dados comum que será utilizada posteriormente.

\paragraph{} Essa estrutura de dados é serializada como um arquivo de texto no formato JSON e persistida em disco. Isso permite que um passo seguinte do fluxo de processamento possa reutilizar o resultado de uma execução prévia deste componente, removendo a necessidade de um novo acesso ao banco de dados de origem.

\paragraph{} O analisador de banco de dados é composto pelo núcleo, pelo plugin de banco de dados, pelo analisador de estrutura e pelo analisador de tipos semânticos.

\subsubsection{Núcleo}

\paragraph{} O núcleo é o subcomponente responsável por agregar os fluxos do programa de extração, orquestrando as chamadas entre os compoenentes para compor a estrutura de dados final.

\paragraph{} O núcleo é responsável por inicializar o fluxo e carregar um plugin de banco de dados.

\subsubsection{Plugin de Banco de Dados}

\paragraph{} O plugin de banco de dados é um módulo que contém as consultas para obtenção de metadados e amostras do banco de dados de entrada.

\paragraph{} Este componente pode ter várias implementações de acordo com o banco de dados de entrada. No escopo deste trabalho, apenas a implementação do plugin para Postgres foi criada.

\subsubsection{Analisador de Estrutura}

\paragraph{} É o subcomponente do analisador de banco de dados responsável por capturar o desenho do banco de dados original, trazendo para o fluxo de dados suas colunas com os respectivos tipos atômicos e tabelas, além de amostras e estatísticas dos dados, a partir da realização das consultas necessarias para obtenção destas informações.

\paragraph{} O analisador de estrutura utilza as consultas fornecidas pelo plugin de banco de dados para obtenção de metadados.


\subsubsection{Analisador de Tipos Semânticos}

\paragraph{} O analisador de tipos semânticos é o componente responsável por obter o significado de uma coluna dentro do contexto das informações presentes no banco de dados a partir de suas amostras e é aplicado em colunas textuais para permitir a futura geração de dados semanticamente coerentes com o banco de dados original.

\paragraph{} Este processo pode ser feito a partir das técnicas previamente apresentadas como busca em dicionário e expressão regulares.

\paragraph{} Estas tecnicas, no entanto, apresentam limitações que as tornam inconvenientes para obtenção de alguns tipos semânticos como por exemplo o endereço.

\paragraph{} Como uma tentativa de contornar este problema e aumentar a abrangência da inferência de tipos semânticos, este componente utiliza uma solução externa criada a partir de técnicas de aprendizado de máquina.

\paragraph{} O sistema externo, chamado SATO\cite{zhang2019sato}, é integrado à solução final a partir de chamadas HTTP. Para cada tabela do banco de origem, o analisador de tipos semânticos cria uma amostra no formato CSV contendo um subconjunto dos seus registros e a envia para a rota de classficação do SATO. Utilizou-se um modelo pré-treinado, incluido no repositório do SATO, chamado Type78.

\paragraph{} Para compatibilidade, utilizou-se um container Docker com as dependências requeridas pelo SATO para fornecer um servidor HTTP que processa as requisições de classificação semantica.

\paragraph{} Desta forma, é possível tipos semânticos de colunas em casos nos quais estes não poderiam ser obtidos.

\paragraph{} A classificação semântica de cada coluna pode então ser utilizada em etapas seguintes do fluxo para geração de dados análogos.

\subsubsection{Extrator Numérico}

\paragraph{} Para colunas de tipos numéricos, há um processamento que visa substituir o conjunto de dados originais com um conjunto cuja distribuição é análoga.

\paragraph{} Para isso, coletam-se amostras do conjunto original. Essas amostras são ordenadas. Um número aleatório é sorteado de uma distribuição uniforme entre 0 e 1 e multiplicado pelo número de amostras.

\paragraph{} A parte inteira deste número sorteado e escalado é utilizada como índice para acessar uma das amostras ordenadas do conjunto original.

\paragraph{} Realiza-se então a interpolação linear dessa amostra e da amostra seguinte, com pesos proporcionais a parte fracionária do número índice. Essa operação gera um novo número que é armazenado em um vetor.

\paragraph{} Esse processo é repetido até gerar um novo conjunto de números que caracteriza o conjunto numérico original. Quando ocorre a geração de dados, este novo conjunto passa pelo mesmo processo para ser expandido e gerar o conteúdo de uma coluna numérica anonimizada.

\paragraph{} Um estudo aprofundado visando discutir valores ótimos para o tamanho do conjunto caracterizador e também das alterações nas funções estatísticas está fora do escopo deste trabalho e será deixada para eventuais continuações.

\subsection{Gerador de Dados}

\paragraph{} O Gerador de dados é o componente responsável pela geração da carga de saída do fluxo de processamento.

\paragraph{} Este componente requer como entrada o arquivo contendo as especificações geradas pelos componentes anteriores e utiliza como parâmetro para geração da estrutura e do conteúdo de um novo banco de dados.

\paragraph{} O primeiro passo do fluxo de geração de dados é a criação das tabelas e suas relações, incluindo chaves primárias e extrangeiras.

\paragraph{} Para criação da estrutura do banco de dados, suas tabelas e colunas, utilizam-se as capacidades fornecidas pelo SQLAlchemy.

\paragraph{} Então, gera-se o conteúdo das tabelas. Para colunas que não possuem um elo com outra tabela, ou seja, que não são chaves estrangeiras, o dado é gerado utilizando um gerador selecionado a partir dos seus tipos atômico e semantico.

\paragraph{} As colunas cujo dado é oriundo de outra tabela a partir de uma relação têm sua criação postergada até que a coluna de origem tenha dados gerados. Os dados gerados da origem são selecionados aleatóriamente para a coluna de destino.